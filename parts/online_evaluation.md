## Online evaluation

<!-- FIXME: Omit online evaluation due to the effort that it requires? -->

The results of offline testing can differ dramatically from the results obtained via online testing done at system runtime with real users [@Said2013].
In particular, the recommender systems research community is reassessing the dominance of offline testing focused on evaluating accuracy metrics.
It is becoming more common to emphasize online testing and non-accuracy metrics, such as recommendation diversity.

Click-through can be reinterpreted as implicit positive rating.

<!--
TODO: In order to be able to interpret CTR correctly, read: T. Joachims, L. Granka, B. Pan, H. Hembrooke, and G. Gay, Accurately interpreting clickthrough data as implicit feedback.
-->

A/B testing

### Evaluated metrics

* Click-through rate

### Evaluation results

<!--
TODO: Qualitative evaluation via interview with public procurement experts to obtain feedback on the quality of recommendations.
-->
